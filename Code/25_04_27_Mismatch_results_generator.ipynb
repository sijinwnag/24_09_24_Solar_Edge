{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6930cce7",
   "metadata": {},
   "source": [
    "# 1. Import & def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23bcee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pvlib\n",
    "import imageio\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import scipy.constants as const\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# define hte directory for the data\n",
    "# data folder direcotry\n",
    "data_dir = r\"C:\\Users\\z5183876\\OneDrive - UNSW\\Documents\\GitHub\\24_09_24_Solar_Edge\\Data\"\n",
    "# direrctory for saving results\n",
    "base_dir = r\"C:\\Users\\z5183876\\OneDrive - UNSW\\Documents\\GitHub\\24_09_24_Solar_Edge\\Results\\25_06_24_Results\"\n",
    "# directory for the results folder to investigate for session 6\n",
    "results_dir = r'C:\\Users\\z5183876\\OneDrive - UNSW\\Documents\\GitHub\\24_09_24_Solar_Edge\\Results\\v_from_i_combined\\iv_curve_plots_20250404_211059_spring_3794347'\n",
    "# directory for the site summary to read from\n",
    "summary_dir = r\"C:\\Users\\z5183876\\OneDrive - UNSW\\Documents\\GitHub\\24_09_24_Solar_Edge\\Data\\25_05_01_Newsites_summary.xlsx\"\n",
    "\n",
    "# Determine fixed x and y axis limits for all plots that plot for each module\n",
    "y_limit_module = (0, 15)\n",
    "x_limit_module = (0, 60)  # Assuming a reasonable range for combined voltages\n",
    "\n",
    "# Determine fixed x and y axis limits for all plots that plot for the combined inverter\n",
    "y_limit_inverter = (0, 17)\n",
    "x_limit_inverter = (0, 1200)  # Adjust for combined voltages\n",
    "\n",
    "# Option to dynamically calculate vth based on panel temperature\n",
    "use_dynamic_vth = True  # Set to True to enable dynamic calculation, False to use thermal_voltage_25C\n",
    "\n",
    "# Option to replace the panel temperature with the temperature, the reason to do this is that the module temperature looks too high but the ambient tmperature looks like module temperature\n",
    "use_a_T = True  # Set to True to use ambient temperature, False to use module temperature\n",
    "\n",
    "# define the plot template\n",
    "axis_label_size = 20\n",
    "axis_num_size = 20\n",
    "text_size = 20\n",
    "title_size = 22\n",
    "\n",
    "# define the figure size for single plot\n",
    "figure_size = (6, 6)\n",
    "subplot_size_1_2 = (6, 6)\n",
    "long_hoz_figsize = (12, 6)\n",
    "\n",
    "# define the function to calculate the I0 at MPPT\n",
    "def I0(I, V, Rs, Rsh, n, N, vth):\n",
    "    # calculate the exponential term\n",
    "    exp_term = np.exp(-(V + I * Rs) / (n * N * vth))\n",
    "    # calculate the fraction term\n",
    "    frac_term = n * N * vth / V\n",
    "    # calculate hte numerator\n",
    "    numerator = I*(1 + Rs/Rsh) - V/Rsh\n",
    "    # calculate the denominator\n",
    "    denominator = 1 - I * Rs / V\n",
    "    # put them together\n",
    "    I0 = numerator / denominator * frac_term * exp_term\n",
    "    return I0\n",
    "\n",
    "# define the function to calculate IL at MPPT\n",
    "def IL(I, V, Rs, Rsh, n, N, vth, I0):\n",
    "    # calculate the first term\n",
    "    first_term = I * (1 + Rs/Rsh)\n",
    "    # calculate the second term\n",
    "    second_term = V / Rsh\n",
    "    # calculate the third term\n",
    "    third_term = I0*(np.exp((V + I * Rs) / (n * N * vth)) - 1)\n",
    "    # put them together\n",
    "    IL = first_term + second_term + third_term\n",
    "    return IL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9395ebe",
   "metadata": {},
   "source": [
    "# 2. Loop through all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cabefbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No  Site ID        Country  State     kWp  Number of modules  Module size  \\\n",
      "0   1  3455043      Australia    QLD   9.960               24.0          415   \n",
      "1   2  4002138      Australia    VIC   6.660               18.0          370   \n",
      "2   3  4034376      Australia     SA   6.650               14.0          475   \n",
      "3   4  4140175      Australia    NSW   6.600               15.0          440   \n",
      "4   5  4186157  North America  Texas  10.695               31.0          345   \n",
      "\n",
      "     Opt                 Module Make                       Module  \\\n",
      "0   S440                      Q Cell       Q.PEAK DUO ML-G10+ 415   \n",
      "1   S440              Canadian solar                   CS3L-370MS   \n",
      "2   S500  JinkoSolar Holding Co. Ltd              JKM475N-60HL4-V   \n",
      "3  S500B          Trina Solar Energy  TSM-440NEG9R.28 (Vertex S+)   \n",
      "4   S440               Mission Solar          \\t\\nMSE345SX5T 345W   \n",
      "\n",
      "                                          Address Orientation Shade  \\\n",
      "0            18 Greene Street, Newmarket, QLD, AU       Multi   Yes   \n",
      "1         184 Blind Creek Road, Cardigan, VIC, AU      Single    No   \n",
      "2        49 Weerana Road, Salisbury Plain, SA, AU      Single    No   \n",
      "3          4 Cromarty Rd, Soldiers Point NSW 2317      Single   Yes   \n",
      "4  2239 Cypress Pearl, San Antonio, TX 78232, USA      Single    No   \n",
      "\n",
      "  PV Syst Module Data Module Datasheet Telemtry Data  \n",
      "0                 Yes              Yes           Yes  \n",
      "1                 Yes              Yes           Yes  \n",
      "2                 Yes              Yes           Yes  \n",
      "3                 Yes              Yes           Yes  \n",
      "4                 Yes              Yes           Yes  \n"
     ]
    }
   ],
   "source": [
    "# Get all site_ids from the folder names in data_dir\n",
    "site_folders = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "site_ids = [folder.split('_')[0] for folder in site_folders]\n",
    "site_ids = ['4111846']\n",
    "\n",
    "# create a list of seasons to loop through\n",
    "seasons = ['spring', 'summer', 'autumn', 'winter']\n",
    "\n",
    "# # Constants for vth calculation\n",
    "boltzmann_constant = const.Boltzmann  # Boltzmann constant in J/K\n",
    "electron_charge = const.e  # Elementary charge in C\n",
    "\n",
    "# read the summary file to get the site_id and the season\n",
    "summary_df = pd.read_excel(summary_dir, sheet_name='Sheet1')\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3600bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site_id: 4111846\n",
      "Season directory found: C:\\Users\\z5183876\\OneDrive - UNSW\\Documents\\GitHub\\24_09_24_Solar_Edge\\Data\\4111846\\march\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z5183876\\AppData\\Local\\Temp\\ipykernel_33148\\627764406.py:185: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  new_index = pd.date_range(start=earliest_timestamp, end=latest_timestamp, freq='5T')\n"
     ]
    }
   ],
   "source": [
    "# for site_id in ['3794347']:\n",
    "for site_id in site_ids:\n",
    "    print(f\"Processing site_id: {site_id}\")\n",
    "\n",
    "    #============= find the site_id directory =============\n",
    "    for season in seasons:\n",
    "    # for season in seasons:\n",
    "        # Find the directory containing the site_id\n",
    "        site_dir = [d for d in os.listdir(data_dir) if site_id in d][0]\n",
    "\n",
    "        # Full path to the site directory\n",
    "        site_dir = os.path.join(data_dir, site_dir)\n",
    "\n",
    "        #============= Get the data =============\n",
    "        # Define a mapping from season to a list of month names (all in lowercase)\n",
    "        season_months_south = {\n",
    "            'summer': ['december', 'january', 'february'],\n",
    "            'autumn': ['march', 'april', 'may'],\n",
    "            'winter': ['june', 'july', 'august'],\n",
    "            'spring': ['september', 'october', 'november']\n",
    "        }\n",
    "        # define a mapping from season to a list of month names for northern hemisphere\n",
    "        season_months_north = {\n",
    "            'summer': ['june', 'july', 'august'],\n",
    "            'autumn': ['september', 'october', 'november'],\n",
    "            'winter': ['december', 'january', 'february'],\n",
    "            'spring': ['march', 'april', 'may']\n",
    "        }\n",
    "\n",
    "        # look up the site id in the summary file to find the corresponding Country\n",
    "        site_info = summary_df[summary_df['Site ID'] == int(site_id)]\n",
    "\n",
    "        # print(\"Site info found:\", site_info)\n",
    "\n",
    "        if site_info['Country'].values[0] == 'Australia':\n",
    "            # Use the southern hemisphere mapping\n",
    "            season_months = season_months_south\n",
    "        else:\n",
    "            # Use the northern hemisphere mapping\n",
    "            season_months = season_months_north\n",
    "\n",
    "        # Ensure the season is in lowercase for matching\n",
    "        season_lower = season.lower()\n",
    "\n",
    "        # Find the folder that contains the season word or any month name corresponding to that season\n",
    "        season_dir_candidates = [\n",
    "            d for d in os.listdir(site_dir)\n",
    "            if (season_lower in d.lower() or any(month in d.lower() for month in season_months.get(season_lower, [])))\n",
    "        ]\n",
    "\n",
    "        if not season_dir_candidates:\n",
    "            raise ValueError(\"No folder found that contains the specified season or its corresponding months.\")\n",
    "\n",
    "        # Choose the first matching folder (or adjust the selection logic as needed)\n",
    "        season_dir = season_dir_candidates[0]\n",
    "\n",
    "        # Full path to the season directory\n",
    "        season_dir = os.path.join(site_dir, season_dir)\n",
    "        print(\"Season directory found:\", season_dir)\n",
    "\n",
    "        # Initialize empty lists to store the DataFrames and reporter IDs\n",
    "        dataframes = []\n",
    "        reporter_ids = []\n",
    "\n",
    "        # Define a list of potential timestamp formats\n",
    "        timestamp_formats = [\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "            \"%d/%m/%Y %H:%M\",\n",
    "            \"%m/%d/%Y %H:%M\",\n",
    "            \"%Y-%d-%m %H:%M:%S\",\n",
    "            None  # Let pandas infer formats\n",
    "        ]\n",
    "\n",
    "        # Get a list of CSV files in the season directory that contain \"optimizer_data\"\n",
    "        csv_files = [f for f in os.listdir(season_dir) if 'optimizer_data' in f and f.endswith('.csv')]\n",
    "\n",
    "        if not csv_files:\n",
    "            raise ValueError(\"No CSV files found in season directory.\")\n",
    "            # go to the next season and site_id\n",
    "            continue\n",
    "\n",
    "        # If only one CSV file exists, check if it contains a 'reporter_id' column.\n",
    "        if len(csv_files) == 1:\n",
    "            file = csv_files[0]\n",
    "            file_path = os.path.join(season_dir, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if 'reporter_id' in df.columns:\n",
    "                # Process the single CSV file by splitting it by reporter_id.\n",
    "                unique_reporters = df['reporter_id'].unique()\n",
    "                for reporter in unique_reporters:\n",
    "                    df_rep = df[df['reporter_id'] == reporter].copy()\n",
    "                    # Rename the first column to \"Timestamp\" if not already\n",
    "                    if df_rep.columns[0] != 'Timestamp':\n",
    "                        df_rep.rename(columns={df_rep.columns[0]: 'Timestamp'}, inplace=True)\n",
    "                    \n",
    "                    # Define a mapping for renaming relevant columns to include the reporter id\n",
    "                    rename_map = {\n",
    "                        'panel_current': f'panel_current_{reporter}',\n",
    "                        'panel_voltage': f'panel_voltage_{reporter}',\n",
    "                        'temperature': f'temperature_{reporter}',\n",
    "                        'panel_temperature': f'panel_temperature_{reporter}',\n",
    "                        'power': f'power_{reporter}'\n",
    "                    }\n",
    "                    df_rep.rename(columns=rename_map, inplace=True)\n",
    "                    \n",
    "                    # Convert the \"Timestamp\" column to datetime using potential formats\n",
    "                    for fmt in timestamp_formats:\n",
    "                        try:\n",
    "                            df_rep['Timestamp'] = pd.to_datetime(df_rep['Timestamp'], format=fmt)\n",
    "                            break\n",
    "                        except (ValueError, TypeError):\n",
    "                            pass\n",
    "                    \n",
    "                    # Set the index to the Timestamp\n",
    "                    df_rep.set_index('Timestamp', inplace=True)\n",
    "                    # Keep only the renamed columns\n",
    "                    df_rep = df_rep[list(rename_map.values())]\n",
    "                    dataframes.append(df_rep)\n",
    "                    reporter_ids.append(str(reporter))\n",
    "            else:\n",
    "                # Single CSV file but without a 'reporter_id' column.\n",
    "                # Treat the entire file as coming from a default reporter.\n",
    "                default_reporter = \"default\"\n",
    "                if df.columns[0] != 'Timestamp':\n",
    "                    df.rename(columns={df.columns[0]: 'Timestamp'}, inplace=True)\n",
    "                rename_map = {\n",
    "                    'panel_current': f'panel_current_{default_reporter}',\n",
    "                    'panel_voltage': f'panel_voltage_{default_reporter}',\n",
    "                    'temperature': f'temperature_{default_reporter}',\n",
    "                    'panel_temperature': f'panel_temperature_{default_reporter}',\n",
    "                    'power': f'power_{default_reporter}'\n",
    "                }\n",
    "                df.rename(columns=rename_map, inplace=True)\n",
    "                for fmt in timestamp_formats:\n",
    "                    try:\n",
    "                        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format=fmt)\n",
    "                        break\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass\n",
    "                df.set_index('Timestamp', inplace=True)\n",
    "                df = df[list(rename_map.values())]\n",
    "                dataframes.append(df)\n",
    "                reporter_ids.append(default_reporter)\n",
    "        else:\n",
    "            # Multiple CSV files case (each file corresponding to one optimizer)\n",
    "            for file in csv_files:\n",
    "                file_path = os.path.join(season_dir, file)\n",
    "                optimizer_data = pd.read_csv(file_path)\n",
    "                \n",
    "                # Extract the reporter_id from the file name (assuming it is the last part before the extension)\n",
    "                reporter_id = file.split('_')[-1].split('.')[0]\n",
    "                reporter_ids.append(reporter_id)\n",
    "                \n",
    "                optimizer_data.rename(columns={\n",
    "                    'panel_current': f'panel_current_{reporter_id}',\n",
    "                    'panel_voltage': f'panel_voltage_{reporter_id}',\n",
    "                    'temperature': f'temperature_{reporter_id}',\n",
    "                    'panel_temperature': f'panel_temperature_{reporter_id}',\n",
    "                    'power': f'power_{reporter_id}'\n",
    "                }, inplace=True)\n",
    "                \n",
    "                if optimizer_data.columns[0] != 'Timestamp':\n",
    "                    optimizer_data.rename(columns={optimizer_data.columns[0]: 'Timestamp'}, inplace=True)\n",
    "                \n",
    "                for fmt in timestamp_formats:\n",
    "                    try:\n",
    "                        optimizer_data['Timestamp'] = pd.to_datetime(optimizer_data['Timestamp'], format=fmt)\n",
    "                        break\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass\n",
    "                \n",
    "                optimizer_data.set_index('Timestamp', inplace=True)\n",
    "                optimizer_data = optimizer_data[[f'panel_current_{reporter_id}', f'panel_voltage_{reporter_id}',\n",
    "                                                f'temperature_{reporter_id}', f'panel_temperature_{reporter_id}',\n",
    "                                                f'power_{reporter_id}']]\n",
    "                dataframes.append(optimizer_data)\n",
    "\n",
    "        # Synchronize timestamps across all DataFrames:\n",
    "        if dataframes:\n",
    "            # Find the overlapping time window by using the maximum start time and the minimum end time.\n",
    "            earliest_timestamp = max([df.index[0] for df in dataframes])\n",
    "            latest_timestamp = min([df.index[-1] for df in dataframes])\n",
    "            # Create a new index with a 5-minute frequency.\n",
    "            new_index = pd.date_range(start=earliest_timestamp, end=latest_timestamp, freq='5T')\n",
    "            \n",
    "            # Reindex each DataFrame, inserting NaN for missing timestamps.\n",
    "            for i in range(len(dataframes)):\n",
    "                for index in new_index:\n",
    "                    if index not in dataframes[i].index:\n",
    "                        dataframes[i].loc[index] = np.nan\n",
    "            \n",
    "            # Merge all DataFrames on the Timestamp index.\n",
    "            merged_data = pd.concat(dataframes, axis=1)\n",
    "            # Reset the index so that Timestamp becomes a column.\n",
    "            merged_data.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "        # remove any rows that contains Nan\n",
    "        # merged_data.dropna(inplace=True)\n",
    "        # print(merged_data)\n",
    "\n",
    "        # Specify the number of days to plot\n",
    "        num_days_to_plot = 10\n",
    "\n",
    "        # Filter the data for the specified number of days\n",
    "        start_date = pd.to_datetime(merged_data['Timestamp'].iloc[0])\n",
    "        end_date = start_date + timedelta(days=num_days_to_plot)\n",
    "        filtered_data = merged_data[(pd.to_datetime(merged_data['Timestamp']) >= start_date) & \n",
    "                                    (pd.to_datetime(merged_data['Timestamp']) < end_date)]\n",
    "        first_month = pd.to_datetime(merged_data['Timestamp'].iloc[0]).strftime('%B')\n",
    "\n",
    "        # print(filtered_data)\n",
    "\n",
    "        # Create a 2x2 subplot for the data\n",
    "        fig, axs = plt.subplots(2, 2, figsize=long_hoz_figsize)  # Use figure size from session 1\n",
    "\n",
    "        # Add a figure-level title with site ID and season\n",
    "        # fig.suptitle(f\"Site ID: {site_id} | Season: {season}\", fontsize=title_size)  # Use title_size\n",
    "\n",
    "        fig.suptitle(f\"Site ID: {site_id} | Month: {first_month}\", fontsize=title_size)  # Use title_size\n",
    "\n",
    "        # Plot all panel currents\n",
    "        for reporter_id in reporter_ids:\n",
    "            axs[0, 0].plot(filtered_data['Timestamp'], filtered_data[f'panel_current_{reporter_id}'])\n",
    "        axs[0, 0].set_title('Panel Current', fontsize=title_size)\n",
    "        axs[0, 0].set_xlabel('Time', fontsize=axis_label_size-5)\n",
    "        axs[0, 0].set_ylabel('Current (A)', fontsize=axis_label_size-5)\n",
    "        axs[0, 0].tick_params(axis='x', which='both', bottom=False, labelbottom=False, labelsize=axis_num_size)\n",
    "        axs[0, 0].tick_params(axis='y', labelsize=axis_num_size)\n",
    "\n",
    "        # Plot all panel voltages\n",
    "        for reporter_id in reporter_ids:\n",
    "            axs[0, 1].plot(filtered_data['Timestamp'], filtered_data[f'panel_voltage_{reporter_id}'])\n",
    "        axs[0, 1].set_title('Panel Voltage', fontsize=title_size)\n",
    "        axs[0, 1].set_xlabel('Time', fontsize=axis_label_size-5)\n",
    "        axs[0, 1].set_ylabel('Voltage (V)', fontsize=axis_label_size-5)\n",
    "        axs[0, 1].tick_params(axis='x', which='both', bottom=False, labelbottom=False, labelsize=axis_num_size)\n",
    "        axs[0, 1].tick_params(axis='y', labelsize=axis_num_size)\n",
    "\n",
    "        # Plot all temperatures\n",
    "        for reporter_id in reporter_ids:\n",
    "            axs[1, 0].plot(filtered_data['Timestamp'], filtered_data[f'temperature_{reporter_id}'])\n",
    "        axs[1, 0].set_title('Temperature', fontsize=title_size)\n",
    "        axs[1, 0].set_xlabel('Time', fontsize=axis_label_size-5)\n",
    "        axs[1, 0].set_ylabel('Temperature (°C)', fontsize=axis_label_size-5)\n",
    "        axs[1, 0].tick_params(axis='x', which='both', bottom=False, labelbottom=False, labelsize=axis_num_size)\n",
    "        axs[1, 0].tick_params(axis='y', labelsize=axis_num_size)\n",
    "\n",
    "        # Plot all panel temperatures\n",
    "        for reporter_id in reporter_ids:\n",
    "            axs[1, 1].plot(filtered_data['Timestamp'], filtered_data[f'panel_temperature_{reporter_id}'])\n",
    "        axs[1, 1].set_title('Panel Temperature', fontsize=title_size)\n",
    "        axs[1, 1].set_xlabel('Time', fontsize=axis_label_size-5)\n",
    "        axs[1, 1].set_ylabel('Panel Temperature (°C)', fontsize=axis_label_size-5)\n",
    "        axs[1, 1].tick_params(axis='x', which='both', bottom=False, labelbottom=False, labelsize=axis_num_size)\n",
    "        axs[1, 1].tick_params(axis='y', labelsize=axis_num_size)\n",
    "\n",
    "        # Adjust layout and show the plot\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Leave space for the suptitle\n",
    "        plt.show()\n",
    "        \n",
    "        # create a new folder for the results, name it as the site_id and season, and the time now\n",
    "        # now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # results_folder = os.path.join(base_dir, f\"v_from_i_combined\\{site_id}_{season}_{now}\")\n",
    "        # os.makedirs(results_folder, exist_ok=True)\n",
    "        # first_month = pd.to_datetime(merged_data['Timestamp'].iloc[0]).strftime('%B')\n",
    "        # now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # results_folder = os.path.join(base_dir, f\"v_from_i_combined\\\\{site_id}_{first_month}_{now}\")\n",
    "        # os.makedirs(results_folder, exist_ok=True)\n",
    "        # Create date-based folder structure\n",
    "        date_folder = datetime.datetime.now().strftime(\"%y_%m_%d_Results\")\n",
    "        # Ensure we use the correct v_from_i_combined path\n",
    "        v_from_i_combined_dir = r\"C:\\Users\\z5183876\\OneDrive - UNSW\\Documents\\GitHub\\24_09_24_Solar_Edge\\Results\\v_from_i_combined\"\n",
    "        date_results_dir = os.path.join(v_from_i_combined_dir, date_folder)\n",
    "        os.makedirs(date_results_dir, exist_ok=True)\n",
    "        \n",
    "        first_month = pd.to_datetime(merged_data['Timestamp'].iloc[0]).strftime('%B')\n",
    "        now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        results_folder = os.path.join(date_results_dir, f\"{site_id}_{first_month}_{now}\")\n",
    "        os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "        # save the figure to the results folder\n",
    "        fig.savefig(os.path.join(results_folder, f\"{site_id}_{season}_data.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to free up memory\n",
    "\n",
    "        if use_a_T:\n",
    "            print(\"Using ambient temperature\")\n",
    "            # Remove any column whose name contains \"panel_temperature\"\n",
    "            cols_to_drop = [col for col in merged_data.columns if 'panel_temperature' in col]\n",
    "            merged_data.drop(columns=cols_to_drop, inplace=True)\n",
    "            \n",
    "            # For each column that contains \"temperature\", create a duplicate column \n",
    "            # with the name changed from \"temperature\" to \"panel_temperature\"\n",
    "            for col in [col for col in merged_data.columns if 'temperature' in col]:\n",
    "                new_col = col.replace('temperature', 'panel_temperature')\n",
    "                merged_data[new_col] = merged_data[col]\n",
    "\n",
    "        #============= Module parameter extraction =============\n",
    "        # find the .PAN file in the site_dir\n",
    "        pan_file = [f for f in os.listdir(site_dir) if f.endswith('.PAN')][0]\n",
    "\n",
    "        # read the .PAN file\n",
    "        pan_file_path = os.path.join(site_dir, pan_file)\n",
    "\n",
    "        with open(pan_file_path, 'r') as f:\n",
    "            pan_data = f.readlines()\n",
    "            # find the line that contains the \"RSeries\"\n",
    "            for line in pan_data:\n",
    "                if 'RSerie' in line: # Note: The original code had 'RSeries' which might be a typo in the PAN file\n",
    "                    series_resistance = float(line.split('=')[1].strip())\n",
    "                    print(f\"Series Resistance from PAN file: {series_resistance}\")\n",
    "            # find the line that contains the \"RShunt\"\n",
    "            for line in pan_data:\n",
    "                if 'RShunt' in line:\n",
    "                    shunt_resistance = float(line.split('=')[1].strip())\n",
    "                    print(f\"Shunt Resistance from PAN file: {shunt_resistance}\")\n",
    "            # find the line that contains the \"NCelS\" as the number of cells in series\n",
    "            for line in pan_data:\n",
    "                if 'NCelS' in line:\n",
    "                    num_cells_series = int(line.split('=')[1].strip())\n",
    "                    print(f\"Number of cells in series from PAN file: {num_cells_series}\")\n",
    "            # find the line that contains the \"Gamma\" as the ideality factor\n",
    "            for line in pan_data:\n",
    "                if 'Gamma' in line:\n",
    "                    ideality_factor = float(line.split('=')[1].strip())\n",
    "                    print(f\"Ideality factor from PAN file: {ideality_factor}\")\n",
    "                    break  # Exit the loop after finding the ideality factor\n",
    "\n",
    "        #============= Loop through timestep and reporter id anlaysis =============\n",
    "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_dir = results_folder\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        image_files = []\n",
    "        max_power_df_combined = pd.DataFrame(columns=['Timestamp', 'Max Voltage (V)', 'Max Current (A)', 'Max Power (W)', 'Voc (V)', 'Isc (A)'])\n",
    "        pmppt_data = pd.DataFrame(columns=['Timestamp', 'Pmppt (W)'])\n",
    "        module_param_df = pd.DataFrame(columns=[\n",
    "            'Timestamp','Optimizer','I0','Isc','Voc','FF','Pmp','Imp','Vmp'\n",
    "        ])\n",
    "        iv_sum_data = pd.DataFrame(columns=['Timestamp', 'Sum of I*V (W)'])  # <-- Added for sum_iv\n",
    "\n",
    "        currents = np.linspace(0, y_limit_inverter[1], 100)\n",
    "\n",
    "        for idx in range(len(merged_data)):\n",
    "            current_timestamp = pd.to_datetime(merged_data['Timestamp'].iloc[idx])\n",
    "\n",
    "            # --- Filter: skip if all measured power is zero ---\n",
    "            all_power_zero = all(\n",
    "                merged_data.get(f'power_{optimiser}', pd.Series([0]*len(merged_data))).iloc[idx] == 0\n",
    "                or np.isnan(merged_data.get(f'power_{optimiser}', pd.Series([0]*len(merged_data))).iloc[idx])\n",
    "                for optimiser in reporter_ids\n",
    "            )\n",
    "            if all_power_zero:\n",
    "                print(f\"Time step {idx} skipped: all measured power is zero.\")\n",
    "                continue\n",
    "\n",
    "            # --- Prepare for all three plots ---\n",
    "            fig_long, axs_long = plt.subplots(1, 3, figsize=long_hoz_figsize)\n",
    "            axs_long[0].set_title(\"Recorded MPP values\", fontsize=title_size, pad=20)\n",
    "            axs_long[0].set_xlim(x_limit_module)\n",
    "            axs_long[0].set_ylim(y_limit_module)\n",
    "            axs_long[0].set_xlabel('Voltage (V)', fontsize=axis_label_size)\n",
    "            axs_long[0].set_ylabel('Current (A)', fontsize=axis_label_size)\n",
    "            # axs_long[0].grid(True)\n",
    "            axs_long[0].tick_params(axis='both', labelsize=axis_num_size)\n",
    "\n",
    "            axs_long[1].set_title(\"Reconstructed I-V curves\", fontsize=title_size, pad=20)\n",
    "            axs_long[1].set_xlim(x_limit_module)\n",
    "            axs_long[1].set_ylim(y_limit_module)\n",
    "            axs_long[1].set_xlabel('Voltage (V)', fontsize=axis_label_size)\n",
    "            axs_long[1].set_ylabel('Current (A)', fontsize=axis_label_size)\n",
    "            # axs_long[1].grid(True)\n",
    "            axs_long[1].tick_params(axis='both', labelsize=axis_num_size)\n",
    "\n",
    "            axs_long[2].set_title(\"Series combined I-V curve\", fontsize=title_size, pad=20)\n",
    "            axs_long[2].set_xlim(x_limit_inverter)\n",
    "            axs_long[2].set_ylim(y_limit_inverter)\n",
    "            axs_long[2].set_xlabel('Voltage (V)', fontsize=axis_label_size)\n",
    "            axs_long[2].set_ylabel('Current (A)', fontsize=axis_label_size)\n",
    "            # axs_long[2].grid(True)\n",
    "            axs_long[2].tick_params(axis='both', labelsize=axis_num_size)\n",
    "\n",
    "            combined_voltage = np.zeros_like(currents)\n",
    "            valid_data_found = False\n",
    "            sum_iv = 0\n",
    "            max_power = np.nan  # Default in case no valid data\n",
    "\n",
    "            for optimiser in reporter_ids:\n",
    "                optimiser_voltage = merged_data[f'panel_voltage_{optimiser}']\n",
    "                optimiser_current = merged_data[f'panel_current_{optimiser}']\n",
    "                panel_temperature = merged_data[f'panel_temperature_{optimiser}']\n",
    "\n",
    "                is_nan_or_zero = (\n",
    "                    optimiser_voltage.iloc[idx] == 0 or\n",
    "                    optimiser_current.iloc[idx] == 0 or\n",
    "                    np.isnan(optimiser_voltage.iloc[idx]) or\n",
    "                    np.isnan(optimiser_current.iloc[idx])\n",
    "                )\n",
    "\n",
    "                # Raw IV data (scatter)\n",
    "                if not is_nan_or_zero:\n",
    "                    panel_voltage = optimiser_voltage.iloc[idx]\n",
    "                    panel_current = optimiser_current.iloc[idx]\n",
    "                    axs_long[0].plot(panel_voltage, panel_current, 'ro', markersize=8, label=f'Opt {optimiser}')\n",
    "                else:\n",
    "                    axs_long[0].plot(0, 0, 'kx', label=f'Opt {optimiser} (no data)')\n",
    "\n",
    "                # Reconstructed IV curves (model)\n",
    "                if is_nan_or_zero:\n",
    "                    voltage = np.zeros_like(currents)\n",
    "                    axs_long[1].plot(voltage, currents, label=f'Opt {optimiser}')\n",
    "                else:\n",
    "                    valid_data_found = True\n",
    "                    panel_temperature_kelvin = panel_temperature.iloc[idx] + 273.15\n",
    "                    vth = boltzmann_constant * panel_temperature_kelvin / electron_charge if use_dynamic_vth else thermal_voltage_25C\n",
    "                    panel_voltage = optimiser_voltage.iloc[idx]\n",
    "                    panel_current = optimiser_current.iloc[idx]\n",
    "                    sum_iv += panel_voltage * panel_current\n",
    "\n",
    "                    I0_op = I0(panel_current, panel_voltage, series_resistance, shunt_resistance, ideality_factor, num_cells_series, vth)\n",
    "                    IL_op = IL(panel_current, panel_voltage, series_resistance, shunt_resistance, ideality_factor, num_cells_series, vth, I0_op)\n",
    "                    params = {\n",
    "                        'photocurrent': IL_op,\n",
    "                        'saturation_current': I0_op,\n",
    "                        'resistance_series': series_resistance,\n",
    "                        'resistance_shunt': shunt_resistance,\n",
    "                        'nNsVth': ideality_factor * num_cells_series * vth\n",
    "                    }\n",
    "                    voltage = pvlib.pvsystem.v_from_i(\n",
    "                        current=currents,\n",
    "                        photocurrent=params['photocurrent'],\n",
    "                        saturation_current=params['saturation_current'],\n",
    "                        resistance_series=params['resistance_series'],\n",
    "                        resistance_shunt=params['resistance_shunt'],\n",
    "                        nNsVth=params['nNsVth']\n",
    "                    )\n",
    "                    axs_long[1].plot(voltage, currents, label=f'Opt {optimiser}')\n",
    "                    axs_long[1].plot(panel_voltage, panel_current, 'ro')\n",
    "\n",
    "                    # Combined IV curve (series)\n",
    "                    results = pvlib.pvsystem.singlediode(**params)\n",
    "                    isc = results['i_sc']\n",
    "                    voc = results['v_oc']\n",
    "                    pmp = results['p_mp']\n",
    "                    imp = results['i_mp']\n",
    "                    vmp = results['v_mp']\n",
    "                    ff = (pmp / (isc * voc)) if (isc > 0 and voc > 0) else np.nan\n",
    "                    voltage = np.where(currents > isc, 0, voltage)\n",
    "                    combined_voltage += voltage\n",
    "\n",
    "                    # append all five\n",
    "                    module_param_df = pd.concat([module_param_df, pd.DataFrame({\n",
    "                        'Timestamp': [current_timestamp],\n",
    "                        'Optimizer': [optimiser],\n",
    "                        'I0':        [I0_op],\n",
    "                        'Isc':       [isc],\n",
    "                        'Voc':       [voc],\n",
    "                        'FF':        [ff],\n",
    "                        'Pmp':       [pmp],\n",
    "                        'Imp':       [imp],\n",
    "                        'Vmp':       [vmp]\n",
    "                    })], ignore_index=True)\n",
    "\n",
    "                if is_nan_or_zero:\n",
    "                    # no-data: record NaNs\n",
    "                    module_param_df = pd.concat([module_param_df, pd.DataFrame({\n",
    "                        'Timestamp': [current_timestamp],\n",
    "                        'Optimizer': [optimiser],\n",
    "                        'I0':        [np.nan],\n",
    "                        'Isc':       [np.nan],\n",
    "                        'Voc':       [np.nan],\n",
    "                        'FF':        [np.nan],\n",
    "                        'Pmp':       [np.nan],\n",
    "                        'Imp':       [np.nan],\n",
    "                        'Vmp':       [np.nan]\n",
    "                    })], ignore_index=True)\n",
    "\n",
    "            # Plot combined IV curve (series)\n",
    "            if valid_data_found:\n",
    "                power = combined_voltage * currents\n",
    "                max_power_idx = np.argmax(power)\n",
    "                max_voltage = combined_voltage[max_power_idx]\n",
    "                max_current = currents[max_power_idx]\n",
    "                max_power = power[max_power_idx]\n",
    "                isc_combined = currents[np.where(combined_voltage > 0)[0][-1]]\n",
    "                voc_combined = combined_voltage[np.where(currents == 0)[0][0]]\n",
    "\n",
    "                axs_long[2].plot(combined_voltage, currents, label='Combined IV Curve')\n",
    "                axs_long[2].plot(max_voltage, max_current, 'ro', label='Max Power Point')\n",
    "                axs_long[2].plot(voc_combined, 0, 'go', label='Voc')\n",
    "                axs_long[2].plot(0, isc_combined, 'bo', label='Isc')\n",
    "\n",
    "                # Save max power and Pmppt\n",
    "                current_timestamp = pd.to_datetime(merged_data['Timestamp'].iloc[idx])\n",
    "                max_power_point = pd.DataFrame({\n",
    "                    'Timestamp': [current_timestamp],\n",
    "                    'Max Voltage (V)': [max_voltage],\n",
    "                    'Max Current (A)': [max_current],\n",
    "                    'Max Power (W)': [max_power],\n",
    "                    'Voc (V)': [voc_combined],\n",
    "                    'Isc (A)': [isc_combined]\n",
    "                })\n",
    "                max_power_df_combined = pd.concat([max_power_df_combined, max_power_point], ignore_index=True)\n",
    "                pmppt_data = pd.concat([pmppt_data, pd.DataFrame({'Timestamp': [current_timestamp], 'Pmppt (W)': [max_power]})], ignore_index=True)\n",
    "\n",
    "            # --- Save sum_iv for this timestep ---\n",
    "            timestamp_title = pd.to_datetime(merged_data['Timestamp'].iloc[idx]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            iv_sum_data = pd.concat([iv_sum_data, pd.DataFrame({'Timestamp': [timestamp_title], 'Sum of I*V (W)': [sum_iv]})], ignore_index=True)\n",
    "\n",
    "            # --- Titles and save ---\n",
    "            percentage_diff_at_time = 0\n",
    "            if sum_iv != 0:\n",
    "                percentage_diff_at_time = ((sum_iv - max_power) / sum_iv) * 100\n",
    "            title_row1 = f\"Site: {site_id} | {timestamp_title}\"\n",
    "            title_row2 = f\"Sum of MPP: {sum_iv:.2f} W | Combined IV MPP: {max_power:.2f} W\"\n",
    "            title_row3 = f\"% Diff: {percentage_diff_at_time:.2f}%\"\n",
    "            fig_long.suptitle(f\"{title_row1}\\n{title_row2}\\n{title_row3}\", fontsize=title_size)\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.90])\n",
    "            file_path = os.path.join(output_dir, f'long_horizontal_{timestamp_title.replace(\":\", \"-\").replace(\" \", \"_\")}.png')\n",
    "            plt.savefig(file_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            image_files.append(file_path)\n",
    "            print(f\"Horizontal comparison plot saved: {file_path}\")\n",
    "\n",
    "        # --- Create a GIF from all horizontal comparison plots ---\n",
    "        gif_path = os.path.join(output_dir, 'combined_iv_curves_long.gif')\n",
    "        with imageio.get_writer(gif_path, mode='I', duration=200, loop=0) as writer:\n",
    "            for filename in image_files:\n",
    "                image = imageio.imread(filename)\n",
    "                writer.append_data(image)\n",
    "        print(f\"GIF saved as: {gif_path}\")\n",
    "\n",
    "        # --- Save the sum of I*V data to an Excel file ---\n",
    "        excel_path = os.path.join(output_dir, 'iv_sum_data.xlsx')\n",
    "        iv_sum_data.to_excel(excel_path, index=False)\n",
    "        print(f\"Excel file saved as: {excel_path}\")\n",
    "\n",
    "        # --- Save the Pmppt data to an Excel file ---\n",
    "        excel_file = os.path.join(output_dir, 'pmppt_data.xlsx')\n",
    "        pmppt_data.to_excel(excel_file, index=False)\n",
    "        print(f\"Excel file saved as: {excel_file}\")\n",
    "\n",
    "        # --- Export J0 data to a CSV file with optimizer IDs as column names ---\n",
    "        params_csv = os.path.join(output_dir, 'module_param_df.csv')\n",
    "        module_param_df.to_csv(params_csv, index=False)\n",
    "        print(f\"Module parameters saved: {params_csv}\")\n",
    "\n",
    "        # ===================== Calcualte hte mismatching loss =====================\n",
    "        # Merge the pmppt_data with the iv_sum_data\n",
    "        combined_data = pd.concat([iv_sum_data, pmppt_data['Pmppt (W)']], axis=1)\n",
    "\n",
    "        # Add season and site ID columns to the combined data\n",
    "        combined_data['Season'] = season\n",
    "        combined_data['Site ID'] = site_id\n",
    "\n",
    "        # Export the combined data to an Excel file with season and site ID in the file name\n",
    "        excel_file = os.path.join(output_dir, f'combined_data_{season}_{site_id}.xlsx')\n",
    "        combined_data.to_excel(excel_file, index=False)\n",
    "\n",
    "        print(f\"Combined data exported to: {excel_file}\")\n",
    "\n",
    "        # Calculate the total energy of Sum of I*V and Pmppt\n",
    "        sum_iv_E = combined_data['Sum of I*V (W)'].sum()\n",
    "        pmppt_E = combined_data['Pmppt (W)'].sum()\n",
    "        sum_mismatch = (sum_iv_E - pmppt_E) / sum_iv_E\n",
    "\n",
    "        # Check if the lengths of Sum of I*V and Pmppt are the same\n",
    "        if len(combined_data['Sum of I*V (W)']) == len(combined_data['Pmppt (W)']):\n",
    "            print(\"The lengths of Sum of I*V and Pmppt are the same.\")\n",
    "        else:\n",
    "            print(\"Warning: The lengths of Sum of I*V and Pmppt are not the same!\")\n",
    "\n",
    "        # Print the total energy for both\n",
    "        print(f\"Sum of I*V Energy: {sum_iv_E:.2f} W\")\n",
    "        print(f\"Pmppt Energy: {pmppt_E:.2f} W\")\n",
    "\n",
    "        # Print the mean mismatch in percentage with 2 decimal places\n",
    "        print(f\"Sum mismatch: {sum_mismatch * 100:.2f}%\")\n",
    "\n",
    "        # ensure the timestamp is in datetime format\n",
    "        combined_data['Timestamp'] = pd.to_datetime(combined_data['Timestamp'])\n",
    "\n",
    "        # Plot the Pmppt and Sum of I*V\n",
    "        fig, ax = plt.subplots(figsize=long_hoz_figsize)\n",
    "\n",
    "        ax.plot(combined_data['Timestamp'],\n",
    "                combined_data['Pmppt (W)'],\n",
    "                label='Series connection',\n",
    "                alpha=0.4)\n",
    "        ax.plot(combined_data['Timestamp'],\n",
    "                combined_data['Sum of I*V (W)'],\n",
    "                label='Sum of maximum powers',\n",
    "                alpha=0.4)\n",
    "\n",
    "        ax.set_xlabel('Time', fontsize=axis_label_size)\n",
    "        ax.set_ylabel('Power (W)', fontsize=axis_label_size)\n",
    "\n",
    "        first_month = pd.to_datetime(combined_data['Timestamp'].iloc[0]).strftime('%B')\n",
    "        ax.set_title(\n",
    "            f'Site ID: {site_id}, Month: {first_month}\\nMismatch: {sum_mismatch * 100:.2f}%',\n",
    "            fontsize=title_size, pad=20\n",
    "        )\n",
    "\n",
    "        ax.legend(loc='upper right', fontsize=axis_num_size-5)\n",
    "\n",
    "        # --- x-axis ticks every 2 days, but shorter & rotated ---\n",
    "        # print(combined_data['Timestamp'].head())\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "        ax.tick_params(axis='x', labelsize=axis_num_size)\n",
    "\n",
    "        # y-axis label size\n",
    "        ax.tick_params(axis='y', labelsize=axis_num_size)\n",
    "\n",
    "        # tighten + more bottom padding\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(bottom=0.20)\n",
    "\n",
    "        # Save + show\n",
    "        plot_file = os.path.join(output_dir, 'pmppt_vs_sum_iv.png')\n",
    "        fig.savefig(plot_file, dpi=300)\n",
    "        print(f\"Plot exported to: {plot_file}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # plot the percentage difference between Pmppt and Sum of I*V over time\n",
    "        fig, ax = plt.subplots(figsize=long_hoz_figsize)\n",
    "        percentage_diff = ((combined_data['Sum of I*V (W)'] - combined_data['Pmppt (W)']) / combined_data['Sum of I*V (W)']) * 100\n",
    "        # if the sum of IV is less than 1, set the percentage difference to 0\n",
    "        percentage_diff[combined_data['Sum of I*V (W)'] < 1] = 0\n",
    "        abs_diff = (combined_data['Sum of I*V (W)'] - combined_data['Pmppt (W)']).abs()\n",
    "\n",
    "        # Plot percentage difference on primary y-axis\n",
    "        ax.plot(combined_data['Timestamp'], percentage_diff, label='Percentage Difference (%)', alpha=0.4, color='orange')\n",
    "        ax.set_xlabel('Time', fontsize=axis_label_size)\n",
    "        ax.set_ylabel('Percentage Difference (%)', fontsize=axis_label_size)\n",
    "\n",
    "        # Create secondary y-axis for absolute difference\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(combined_data['Timestamp'], abs_diff, label='Absolute Difference (W)', alpha=0.4, color='blue')\n",
    "        ax2.set_ylabel('Absolute Difference (W)', fontsize=axis_label_size)\n",
    "\n",
    "        first_month = pd.to_datetime(combined_data['Timestamp'].iloc[0]).strftime('%B')\n",
    "        ax.set_title(\n",
    "            f'Site ID: {site_id}, Month: {first_month}\\nMismatch: {sum_mismatch * 100:.2f}%',\n",
    "            fontsize=title_size, pad=20\n",
    "        )\n",
    "\n",
    "        # Combine legends from both axes\n",
    "        lines_1, labels_1 = ax.get_legend_handles_labels()\n",
    "        lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "        ax2.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper right', fontsize=axis_num_size-5)\n",
    "\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "        ax.tick_params(axis='x', labelsize=axis_num_size)\n",
    "        ax.tick_params(axis='y', labelsize=axis_num_size)\n",
    "        ax2.tick_params(axis='y', labelsize=axis_num_size)\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(bottom=0.20)\n",
    "        # Save + show\n",
    "        plot_file = os.path.join(output_dir, 'percentage_difference.png')\n",
    "        fig.savefig(plot_file, dpi=300)\n",
    "        plt.show()\n",
    "        print(f\"Percentage difference plot exported to: {plot_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
